name: Fetch Hotels from Google

on:
  workflow_dispatch:
    inputs:
      keywords:
        description: "Comma-separated search keywords"
        type: string
        default: "hotel,resort,guest house,aparthotel,boutique hotel,hostel,camp"
      centers:
        description: 'Semicolon-separated "lat,lng" points'
        type: string
        default: "23.611,58.471;23.585,58.407;23.620,58.280;23.600,58.545;23.560,58.640;23.570,58.420;23.520,58.385;23.640,58.520"
      radius:
        description: "Search radius (meters)"
        type: string
        default: "8000"
      basic_only:
        description: "Only core detail fields (no hours/editorial)"
        type: boolean
        default: true
      max_pages_per_query:
        description: "Max pages per (keyword,center)"
        type: string
        default: "2"
      max_places:
        description: "Stop after N unique places overall"
        type: string
        default: "150"
      details_throttle_sec:
        description: "Sleep seconds between Details calls"
        type: string
        default: "0.2"
      wall_timeout_sec:
        description: "Abort run after this many seconds"
        type: string
        default: "1200"
      no_favicons:
        description: "Do NOT set favicon URLs in logo_url"
        type: boolean
        default: false

permissions:
  contents: write

jobs:
  fetch:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Ensure folders exist
        run: |
          mkdir -p data/sources
          mkdir -p assets/hotels

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then
            pip install -r requirements.txt
          else
            pip install requests
          fi

      - name: Run fetcher
        working-directory: scripts
        run: |
          ARGS=()
          ARGS+=(--keywords "${{ github.event.inputs.keywords }}")
          ARGS+=(--centers "${{ github.event.inputs.centers }}")
          ARGS+=(--radius "${{ github.event.inputs.radius }}")
          ARGS+=(--max-pages-per-query "${{ github.event.inputs.max_pages_per_query }}")
          ARGS+=(--max-places "${{ github.event.inputs.max_places }}")
          ARGS+=(--details-throttle-sec "${{ github.event.inputs.details_throttle_sec }}")
          ARGS+=(--wall-timeout-sec "${{ github.event.inputs.wall_timeout_sec }}")
          if [ "${{ github.event.inputs.basic_only }}" = "true" ]; then
            ARGS+=(--basic-only)
          fi
          if [ "${{ github.event.inputs.no_favicons }}" = "true" ]; then
            ARGS+=(--no-favicons)
          fi
          echo "Running: python fetch_hotels.py ${ARGS[*]}"
          python fetch_hotels.py "${ARGS[@]}"

      - name: Filter to Muscat polygon
        shell: bash
        run: |
          cat > /tmp/filter_poly.py <<'PY'
import csv
from pathlib import Path

csv_path = Path("data/sources/hotels.csv")

# Polygon defined as list of (lng, lat) pairs, clockwise or counterclockwise.
# This example outlines coastal Muscat incl. Yiti/Shangri-La/Al Bustan/Qurum/Seeb.
MUSCAT_POLY = [
    (58.260, 23.655),
    (58.225, 23.610),
    (58.260, 23.560),
    (58.360, 23.540),
    (58.430, 23.540),
    (58.510, 23.520),
    (58.590, 23.520),
    (58.650, 23.560),
    (58.705, 23.555),
    (58.735, 23.545),
    (58.625, 23.575),
    (58.690, 23.600),
    (58.600, 23.650),
    (58.520, 23.640),
    (58.420, 23.640),
    (58.340, 23.650),
]

# Loose bounding box (lng_min, lng_max, lat_min, lat_max) for quick reject
BBOX = (58.20, 58.76, 23.48, 23.70)

def point_in_poly(lat, lng, poly):
    # Even-odd rule, expects 'poly' as [(lng,lat),...]
    inside = False
    j = len(poly) - 1
    for i in range(len(poly)):
        xi, yi = poly[i]
        xj, yj = poly[j]
        intersect = ((yi > lat) != (yj > lat)) and \
                    (lng < (xj - xi) * (lat - yi) / (yj - yi + 1e-12) + xi)
        if intersect:
            inside = not inside
        j = i
    return inside

rows_out = []
with csv_path.open(newline="", encoding="utf-8") as f:
    rdr = csv.DictReader(f)
    fieldnames = rdr.fieldnames or []
    for r in rdr:
        try:
            lat = float((r.get("lat") or "").strip())
            lng = float((r.get("lng") or "").strip())
        except Exception:
            continue
        if not (BBOX[0] <= lng <= BBOX[1] and BBOX[2] <= lat <= BBOX[3]):
            continue
        if point_in_poly(lat, lng, MUSCAT_POLY):
            rows_out.append(r)

with csv_path.open("w", newline="", encoding="utf-8") as f:
    w = csv.DictWriter(f, fieldnames=fieldnames)
    w.writeheader()
    w.writerows(rows_out)

print(f"[filter_poly] kept {len(rows_out)} rows inside Muscat polygon.")
PY
          python /tmp/filter_poly.py

      - name: Build tools.json from CSV (optional)
        env:
          PYTHONPATH: ${{ github.workspace }}
        run: |
          if [ -f scripts/ingest/csv_to_tools.py ]; then
            python -m scripts.ingest.csv_to_tools || true
          else
            echo "csv_to_tools.py not found; skipping."
          fi

      - name: Commit & push changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Fetch hotels, filter to Muscat polygon, rebuild tools.json"
          branch: ${{ github.ref_name }}
          file_pattern: |
            data/sources/hotels.csv
            data/tools.json
