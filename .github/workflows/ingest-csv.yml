name: Ingest CSV → Build Data

on:
  workflow_dispatch:
  push:
    paths:
      - "data/sources/*.csv"
      - "scripts/**"
      - "data/schema/**"
      - "assets/**"

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-data:
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: ${{ github.workspace }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ensure scripts is a package
        run: |
          touch scripts/__init__.py
          touch scripts/ingest/__init__.py
          touch scripts/utils/__init__.py
          touch scripts/qa/__init__.py
          touch scripts/media/__init__.py

      - name: CSV → tools.json
        run: python -m scripts.ingest.csv_to_tools

      # ---- Map CSV fields to what the frontend expects (images/actions/categories), but only if hero file exists ----
      - name: Patch tools.json for images/actions (safe mapping)
        run: |
          python - << 'PY'
          import json, pathlib, re, os
          P = pathlib.Path("data/tools.json")
          d = json.loads(P.read_text(encoding="utf-8"))
          changed = 0

          def slugify(s: str) -> str:
              s = (s or "").strip().lower()
              s = re.sub(r"[^a-z0-9]+","-", s)
              s = re.sub(r"(^-|-$)","", s)
              return s or "item"

          def norm_local(path: str) -> str:
              return (path or "").lstrip("/")  # make relative for GH Pages project sites

          def local_exists(path: str) -> bool:
              return path and not path.lower().startswith(("http://","https://")) and os.path.exists(path)

          for o in d:
              # 1) actions.website / actions.phone fallback
              actions = o.setdefault("actions", {})
              if o.get("website") and not actions.get("website"):
                  actions["website"] = o["website"]
              if o.get("phone") and not actions.get("phone"):
                  actions["phone"] = o["phone"]

              # 2) Prefer an actual local hero image that EXISTS
              imgs = o.setdefault("images", {})
              hero = imgs.get("hero") or o.get("hero_url") or ""

              # Normalize if already local
              if hero and not hero.lower().startswith(("http://","https://")):
                  hero = norm_local(hero)

              use_hero = ""
              if local_exists(hero):
                  use_hero = hero
              else:
                  slug = o.get("slug") or slugify(o.get("name",""))
                  candidate = f"assets/images/{slug}/hero.webp"
                  if local_exists(candidate):
                      use_hero = norm_local(candidate)

              # Only set image fields if we have a real local file
              if use_hero:
                  imgs["hero"] = use_hero
                  o["hero_url"] = use_hero  # back-compat
                  # Common aliases some templates use
                  o.setdefault("banner_image", use_hero)
                  o.setdefault("image", use_hero)
                  o.setdefault("cover", use_hero)
                  o.setdefault("cover_image", use_hero)
                  o.setdefault("heroImage", use_hero)
                  o.setdefault("thumbnail", use_hero)

              # 3) Ensure categories[] exists
              if not o.get("categories"):
                  cat = o.get("category")
                  if cat:
                      o["categories"] = [cat]

              changed += 1

          P.write_text(json.dumps(d, ensure_ascii=False, indent=2), encoding="utf-8")
          print(f"Patched {changed} items in data/tools.json (images set only when local file exists)")
          PY

      # ---- Optional: print which items still don't have a local hero.webp (for debugging) ----
      - name: Report items missing local hero.webp
        run: |
          python - << 'PY'
          import json, pathlib, os
          P = pathlib.Path("data/tools.json")
          d = json.loads(P.read_text(encoding="utf-8"))
          missing = []
          for o in d:
              hero = (o.get("images") or {}).get("hero") or o.get("hero_url")
              if not hero or hero.startswith("http"):
                  missing.append(o.get("name") or o.get("slug"))
              else:
                  if not os.path.exists(hero.lstrip("/")):
                      missing.append(o.get("name") or o.get("slug"))
          if missing:
              print("Missing local hero.webp for:")
              for m in missing:
                  print(" -", m)
          else:
              print("All items have local hero.webp")
          PY

      # (Removed hydrate step to avoid Google API usage/cost)

      - name: Sanitize hours after enrich (remove empty weekly)
        run: |
          python - << 'PY'
          import json
          p="data/tools.json"
          with open(p, encoding="utf-8") as f:
              data = json.load(f)
          changed = 0
          for obj in data:
            h = obj.get("hours")
            if isinstance(h, dict) and isinstance(h.get("weekly"), dict) and not h["weekly"]:
              obj.pop("hours", None)
              changed += 1
          with open(p, "w", encoding="utf-8") as f:
              json.dump(data, f, ensure_ascii=False, indent=2)
          print(f"Sanitized entries: {changed}")
          PY

      - name: Verify data/tools.json presence & category counts
        run: |
          ls -la data || true
          python - << 'PY'
          import json, collections
          d=json.load(open("data/tools.json",encoding="utf-8"))
          print("TOTAL RECORDS:", len(d))
          counts=collections.Counter()
          for o in d:
            for c in (o.get("categories") or []):
              counts[c]+=1
          print("CATEGORY COUNTS:", dict(counts))
          print("FIRST 5 SLUGS:", [o.get("slug") for o in d[:5]])
          PY

      - name: Validate schema (blocking if present)
        run: |
          if [ -f data/schema/tools.schema.json ]; then
            python -m scripts.qa.validate_schema data/tools.json data/schema/tools.schema.json
          else
            echo "No schema file; skipping"
          fi

      - name: Commit data artifacts
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/tools.json assets/images || true
          git diff --staged --quiet || git commit -m "data: update tools + images"
          git push

      # ---- Deploy to GitHub Pages ----
      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Upload site artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '.'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
