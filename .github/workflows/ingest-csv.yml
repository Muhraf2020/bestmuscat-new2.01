name: Ingest CSV → Build Data

on:
  workflow_dispatch:
  push:
    paths:
      - "data/sources/*.csv"
      - "scripts/**"
      - "data/schema/**"
      - "assets/**"

permissions:
  contents: write
  pages: write
  id-token: write

jobs:
  build-data:
    runs-on: ubuntu-latest
    env:
      PYTHONPATH: ${{ github.workspace }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ensure scripts is a package
        run: |
          touch scripts/__init__.py
          touch scripts/ingest/__init__.py
          touch scripts/utils/__init__.py
          touch scripts/qa/__init__.py
          touch scripts/media/__init__.py

      - name: CSV → tools.json
        run: python -m scripts.ingest.csv_to_tools

      # ---- Map CSV fields to what the frontend expects (images/actions/categories) ----
      - name: Patch tools.json for images/actions (mapping fixes)
        run: |
          python - << 'PY'
          import json, pathlib, re
          P = pathlib.Path("data/tools.json")
          d = json.loads(P.read_text(encoding="utf-8"))
          changed = 0

          def slugify(s: str) -> str:
              s = (s or "").strip().lower()
              s = re.sub(r"[^a-z0-9]+","-", s)
              s = re.sub(r"(^-|-$)","", s)
              return s or "item"

          for o in d:
              # 1) actions.website / actions.phone from top-level (fallback)
              actions = o.setdefault("actions", {})
              if o.get("website") and not actions.get("website"):
                  actions["website"] = o["website"]
              if o.get("phone") and not actions.get("phone"):
                  actions["phone"] = o["phone"]

              # 2) Preferred hero path: local image downloaded by cache workflow.
              #    Accept either images.hero or top-level hero_url.
              imgs = o.setdefault("images", {})
              hero = imgs.get("hero") or o.get("hero_url") or ""

              # Normalize to relative repo path (no leading slash) for GH Pages project sites.
              if isinstance(hero, str) and hero and not hero.lower().startswith(("http://","https://")):
                  hero = hero.lstrip("/")
                  imgs["hero"] = hero
                  o["hero_url"] = hero  # back-compat

              # If still missing, build a conventional path from slug.
              if not imgs.get("hero"):
                  slug = o.get("slug") or slugify(o.get("name",""))
                  candidate = f"assets/images/{slug}/hero.webp"
                  imgs["hero"] = candidate
                  o.setdefault("hero_url", candidate)

              # 3) Provide multiple aliases some templates might read
              hero_rel = imgs.get("hero") or o.get("hero_url")
              if hero_rel:
                  o.setdefault("banner_image", hero_rel)
                  o.setdefault("image", hero_rel)
                  o.setdefault("cover", hero_rel)
                  o.setdefault("cover_image", hero_rel)
                  o.setdefault("heroImage", hero_rel)
                  o.setdefault("thumbnail", hero_rel)

              # 4) Ensure categories[] exists
              if not o.get("categories"):
                  cat = o.get("category")
                  if cat:
                      o["categories"] = [cat]

              changed += 1

          P.write_text(json.dumps(d, ensure_ascii=False, indent=2), encoding="utf-8")
          print(f"Patched {changed} items in data/tools.json")
          PY

      # (Removed hydrate step to avoid Google API usage/cost)

      - name: Sanitize hours after enrich (remove empty weekly)
        run: |
          python - << 'PY'
          import json
          p="data/tools.json"
          with open(p, encoding="utf-8") as f:
              data = json.load(f)
          changed = 0
          for obj in data:
            h = obj.get("hours")
            if isinstance(h, dict) and isinstance(h.get("weekly"), dict) and not h["weekly"]:
              obj.pop("hours", None)
              changed += 1
          with open(p, "w", encoding="utf-8") as f:
              json.dump(data, f, ensure_ascii=False, indent=2)
          print(f"Sanitized entries: {changed}")
          PY

      - name: Verify data/tools.json presence & category counts
        run: |
          ls -la data || true
          python - << 'PY'
          import json, collections
          d=json.load(open("data/tools.json",encoding="utf-8"))
          print("TOTAL RECORDS:", len(d))
          counts=collections.Counter()
          for o in d:
            for c in (o.get("categories") or []):
              counts[c]+=1
          print("CATEGORY COUNTS:", dict(counts))
          print("FIRST 5 SLUGS:", [o.get("slug") for o in d[:5]])
          PY

      - name: Validate schema (blocking if present)
        run: |
          if [ -f data/schema/tools.schema.json ]; then
            python -m scripts.qa.validate_schema data/tools.json data/schema/tools.schema.json
          else
            echo "No schema file; skipping"
          fi

      - name: Commit data artifacts
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add data/tools.json assets/images || true
          git diff --staged --quiet || git commit -m "data: update tools + images"
          git push

      # ---- Deploy to GitHub Pages ----
      - name: Configure Pages
        uses: actions/configure-pages@v5

      - name: Upload site artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: '.'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
